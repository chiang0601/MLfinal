{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "18jeqNyJFtu7BXogOFmSdX--k1c1voojw",
      "authorship_tag": "ABX9TyP9W4+vbDM2EZFe95Fya9CS"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dmo_3PHc0G-R",
        "outputId": "1e9ffd5e-e29d-4cec-df4a-1f28ec00efd6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import numpy as np\n",
        "\n",
        "boards = [['Gossiping', 39330], ['Stock', 8145], ['C_chat', 17685], ['movie', 10426], ['NBA', 6513], ['Lifeismoney', 4003], [\"Tech_Job\", 4004], ['Food', 7002]]\n",
        "url = 'https://www.ptt.cc/'\n",
        "\n",
        "for board in boards:\n",
        "  titles=[[],[],[]]\n",
        "  for i in range(200) :\n",
        "    web_name = 'https://www.ptt.cc/bbs/' + board[0] + '/index'+ str(board[1]-i) + '.html'\n",
        "    web = requests.get(web_name, cookies={'over18':'1'}, allow_redirects=False)\n",
        "    web.encoding = 'utf-8'\n",
        "    soup = BeautifulSoup(web.text, \"html.parser\")\n",
        "    title = soup.find_all('div', class_='title')\n",
        "    for j in title:\n",
        "      if j.find('a') != None:\n",
        "        URL = url + j.find('a')['href']\n",
        "        response = requests.get(URL, cookies={'over18':'1'}, allow_redirects=False)\n",
        "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "        header = soup.find_all('span','article-meta-value')\n",
        "        if (header==[]) :\n",
        "          continue\n",
        "        titles[0].append(j.find('a').get_text())\n",
        "        titles[1].append(board[0])\n",
        "        main_container = soup.find(id='main-container')\n",
        "        all_text = main_container.text\n",
        "        pre_text = all_text.split('--')[0]\n",
        "\n",
        "        texts = pre_text.split('\\n')\n",
        "        contents = texts[2:]\n",
        "        content = '\\n'.join(contents)\n",
        "        titles[2].append(content)\n",
        "\n",
        "  df = pd.DataFrame(np.transpose(titles), columns=['標題', '分類', '內文'])\n",
        "  f_name = '/content/drive/MyDrive/Colab Notebooks/ppt_test/1' + board[0] + '.csv'\n",
        "  df.to_csv(f_name)\n"
      ],
      "metadata": {
        "id": "1cNbawtgQsR4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZLRkw92cB7XM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}